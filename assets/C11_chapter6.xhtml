<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" dir="ltr" lang="en" xml:lang="en">
<head>
<meta charset="UTF-8"/>
<title>6 Linear Algebra</title>
<link href="../styles/9781000426359.css" rel="stylesheet" type="text/css"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
jax: ["input/TeX","input/MathML","output/SVG"],
extensions: ["tex2jax.js","mml2jax.js","MathEvents.js"],
TeX: {
extensions: ["noErrors.js","noUndefined.js","autoload-all.js"]
},
MathMenu: {
showRenderer: false
},
menuSettings: {
zoom: "Click"
},
messageStyle: "none"
});
</script>
<script src="../mathjax/MathJax.js" type="text/javascript"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006665500" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter">
<section epub:type="chapter" role="doc-chapter">
<h1 class="chapz" id="c6"><a id="index_term8"/><a id="term-264"/><a id="term-265"/><a id="term-503"/><a id="term-504"/><a id="term-581"/><span aria-label="107" epub:type="pagebreak" id="pg_107" role="doc-pagebreak"/><a epub:type="backlink" href="C02a_toc.xhtml#rc6" role="doc-backlink"><span class="green"><span class="big1">6</span><br/>Linear Algebra</span></a></h1>
<p>Perhaps, the most universal tools of graphics programs are the matrices that change or <em>transform</em> points and vectors. In the next chapter, we will see how a vector can be represented as a matrix with a single column, and how the vector can be represented in a different basis via multiplication with a square matrix. We will also describe how we can use such multiplications to accomplish changes in the vector such as scaling, rotation, and translation. In this chapter, we review basic linear algebra from a geometric perspective, focusing on intuition and algorithms that work well in the two- and three-dimensional case.</p>
<p>This chapter can be skipped by readers comfortable with <a id="index_term680"/>linear algebra. However, there may be some enlightening tidbits even for such readers, such as the development of determinants and the discussion of singular and eigenvalue decomposition.</p>
<figure id="f6_1" tabindex="0">
<img alt="" src="../images/fig6_1.jpg"/>
<figcaption><p><span class="blue">Figure 6.1.</span> The signed area of the <a id="index_term819"/>parallelogram is |<strong>ab</strong>|, and in this case the area is positive.</p></figcaption>
</figure>
<section>
<h2 id="sec6_1"><a epub:type="backlink" href="C02a_toc.xhtml#rsec6_1" role="doc-backlink"><span class="green">6.1 Determinants</span></a></h2>
<p>We usually think of determinants as arising in the solution of linear equations. However, for our purposes, we will think of determinants as another way to multiply vectors. For 2D vectors <strong>a</strong> and <strong>b</strong>, the determinant |<strong>ab</strong>| is the area of the parallelogram formed by <strong>a</strong> and <strong>b</strong> (<a href="C11_chapter6.xhtml#f6_1">Figure 6.1</a>). This is a signed area, and the sign is positive if <strong>a</strong> and <strong>b</strong> are right-handed and negative if they are left-handed. This means |<strong>ab</strong>| = <em>–|</em><strong>ba</strong>|. In 2D, we can interpret “right-handed” as meaning we rotate the first vector counterclockwise to close the smallest angle to the second vector. In 3D, the determinant must be taken with three vectors at a time. For <a id="term-582"/><span aria-label="108" epub:type="pagebreak" id="pg_108" role="doc-pagebreak"/>three 3D vectors, <strong>a</strong>, <strong>b</strong>, and <strong>c</strong>, the determinant |<strong>abc</strong>| is the signed volume of the parallelepiped (3D parallelogram; a sheared 3D box) formed by the three vectors (<a href="C11_chapter6.xhtml#f6_2">Figure 6.2</a>). To compute a 2D determinant, we first need to establish a few of its properties. We note that scaling one side of a parallelogram scales its area by the same fraction (<a href="C11_chapter6.xhtml#f6_3">Figure 6.3</a>):</p>
<figure id="f6_2" tabindex="0">
<img alt="" src="../images/fig6_2.jpg"/>
<figcaption><p><span class="blue">Figure 6.2.</span> The signed volume of the parallelepiped shown is denoted by the determinant |abc|, and in this case the volume is positive because the vectors form a righthanded basis.</p></figcaption>
</figure>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mrow><m:mo>(</m:mo><m:mi>k</m:mi><m:mtext>a</m:mtext><m:mo>)</m:mo><m:mtext>b</m:mtext></m:mrow><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>a</m:mtext><m:mrow><m:mo>(</m:mo><m:mi>k</m:mi><m:mtext>b</m:mtext><m:mo>)</m:mo></m:mrow><m:mo>|</m:mo><m:mo>=</m:mo><m:mi>k</m:mi><m:mrow><m:mo>|</m:mo><m:mtext>ab</m:mtext><m:mo>|</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>Also, we note that “shearing” a parallelogram does not change its area (<a href="C11_chapter6.xhtml#f6_4">Figure 6.4</a>):</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mrow><m:mo>(</m:mo><m:mtext>a+</m:mtext><m:mi>k</m:mi><m:mstyle><m:mrow><m:mtext>b</m:mtext></m:mrow></m:mstyle><m:mo>)</m:mo></m:mrow><m:mtext>b</m:mtext><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>a</m:mtext><m:mrow><m:mo>(</m:mo><m:mtext>b</m:mtext><m:mo>+</m:mo><m:mi>k</m:mi><m:mtext>a</m:mtext><m:mo>)</m:mo></m:mrow><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>ab</m:mtext><m:mo>|</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>Finally, we see that the determinant has the following property:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mrow><m:mo>(</m:mo><m:mtext>a+</m:mtext><m:mi>k</m:mi><m:mstyle><m:mrow><m:mtext>b</m:mtext></m:mrow></m:mstyle><m:mo>)</m:mo></m:mrow><m:mtext>b</m:mtext><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>a</m:mtext><m:mrow><m:mo>(</m:mo><m:mtext>b</m:mtext><m:mo>+</m:mo><m:mi>k</m:mi><m:mtext>a</m:mtext><m:mo>)</m:mo></m:mrow><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>ab</m:mtext><m:mo>|</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.1)</m:mo></m:math>
</div>
<p>because as shown in <a href="C11_chapter6.xhtml#f6_5">Figure 6.5</a>, we can “slide” the edge between the two parallelograms over to form a single parallelogram without changing the area of either of the two original parallelograms.</p>
<p>Now let’s assume a Cartesian representation for <strong>a</strong> and <strong>b</strong>:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>|</m:mo><m:mtext>ab</m:mtext><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:mrow><m:mo>|</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:mtext>x</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:mtext>y</m:mtext><m:mo>)</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mtext>x</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mtext>y</m:mtext><m:mo>)</m:mo></m:mrow></m:mrow><m:mo>|</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>|</m:mo><m:mtext>xx</m:mtext><m:mo>|</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>|</m:mo><m:mtext>xy</m:mtext><m:mo>|</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>|</m:mo><m:mtext>yx</m:mtext><m:mo>|</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>|</m:mo><m:mtext>yy</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow></m:mrow></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>)</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mo>+</m:mo><m:mn>1</m:mn><m:mo>)</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mo>−</m:mo><m:mn>1</m:mn><m:mo>)</m:mo><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:mn>0</m:mn><m:mo>)</m:mo></m:mrow></m:mrow></m:mrow></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>This simplification uses the fact that |<strong>vv</strong>| = 0 for any vector <strong>v</strong>, because the parallelograms would all be collinear with <strong>v</strong> and thus without area.</p>
<figure id="f6_3" tabindex="0">
<img alt="" src="../images/fig6_3.jpg"/>
<figcaption><p><span class="blue">Figure 6.3.</span> Scaling a parallelogram along one direction changes the area in the same proportion.</p></figcaption>
</figure>
<p>In three dimensions, the determinant of three 3D vectors <strong>a</strong>, <strong>b</strong>,and <strong>c</strong> is denoted <strong>|abc</strong>|. With Cartesian representations for the vectors, there are analogous rules for parallelepipeds as there are for parallelograms, and we can do an analogous expansion as we did for 2D:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo><m:mtext>abc</m:mtext><m:mo>|</m:mo></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mrow><m:mo>|</m:mo><m:msub><m:mrow><m:mo>(</m:mo><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:mtext>x</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:mtext>y</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:mtext>z)</m:mtext><m:msub><m:mrow><m:mo>(</m:mo><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mtext>x</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mtext>y</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mtext>z)</m:mtext><m:msub><m:mrow><m:mo>(</m:mo><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>x</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>y</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>z)</m:mtext><m:mo>|</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>As you can see, the computation of determinants in this fashion gets uglier as the dimension increases. We will discuss less error-prone ways to compute determinants in <a href="C11_chapter6.xhtml#sec6_3">Section 6.3</a>.</p>
<figure id="f6_4" tabindex="0">
<img alt="" src="../images/fig6_4.jpg"/>
<figcaption><p><span class="blue">Figure 6.4.</span> Shearing a parallelogram does not change its area. These four parallelograms have the same length base and thus the same area.</p></figcaption>
</figure>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 2</span> Determinants arise naturally when computing the expression for one vector as a linear combination of two others—for example, if we wish to express a vector <strong>c</strong> as a combination of vectors <strong>a</strong> and <strong>b</strong>:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>c</m:mtext><m:mo>=</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>a</m:mtext><m:mo>+</m:mo><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>b.</m:mtext></m:mrow></m:math>
</div>
<figure id="f6_5" tabindex="0">
<img alt="" src="../images/fig6_5.jpg"/>
<figcaption><p><span class="blue">Figure 6.5.</span> <a id="term-583"/><span aria-label="109" epub:type="pagebreak" id="pg_109" role="doc-pagebreak"/>The geometry behind Equation 6.1. Both of the parallelograms on the left can be sheared to cover the single parallelogram on the right.</p></figcaption>
</figure>
<figure id="f6_6" tabindex="0">
<img alt="" src="../images/fig6_6.jpg"/>
<figcaption><p><span class="blue">Figure 6.6.</span> On the left, the vector c can be represented using two basis vectors as <em>a</em><sub>c</sub><strong>a</strong> + <em>b</em><sub>c</sub><strong>b</strong>. On the right, we see that the parallelogram formed by <strong>a</strong> and <strong>c</strong> is a sheared version of the parallelogram formed by <em>b</em><sub>c</sub><strong>b</strong> and <strong>a.</strong></p></figcaption>
</figure>
<p class="noindent1">We can see from <a href="C11_chapter6.xhtml#f6_6">Figure 6.6</a> that</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mtext>b</m:mtext><m:mo>)</m:mo><m:mtext>a</m:mtext></m:mrow><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>ca</m:mtext><m:mo>|</m:mo><m:mo>,</m:mo></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>because these parallelograms are just sheared versions of each other. Solving for <em>b<sub>c</sub></em> yields</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>=</m:mo><m:mfrac><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>ca</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>ba</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>An analogous argument yields</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msub><m:mo>=</m:mo><m:mfrac><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>bc</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>ba</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>This is the two-dimensional version of <em><a id="index_term275"/>Cramer’s rule</em> which we will revisit in <a href="C11_chapter6.xhtml#sec6_3_2">Section 6.3.2</a>.</p>
</aside>
</section>
<section>
<h2 id="sec6_2"><a id="index_term686"/><a epub:type="backlink" href="C02a_toc.xhtml#rsec6_2" role="doc-backlink"><span class="green">6.2 Matrices</span></a></h2>
<p>A matrix is an array of numeric elements that follow certain arithmetic rules. An example of a matrix with two rows and three columns is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1.7</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>1.2</m:mn></m:mtd><m:mtd><m:mn>4.2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3.0</m:mn></m:mtd><m:mtd><m:mn>4.5</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>7.2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/><m:mtd/></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:math>
</div>
<p><span aria-label="110" epub:type="pagebreak" id="pg_110" role="doc-pagebreak"/>Matrices are frequently used in computer graphics for a variety of purposes including representation of spatial transforms. For our discussion, we assume the elements of a matrix are all real numbers. This chapter describes both the mechanics of matrix <a id="index_term710"/>arithmetic and the <em>determinant</em> of “square” matrices, i.e., matrices with the same number of rows as columns.</p>
<section>
<h3 id="sec6_2_1"><span class="green">6.2.1 Matrix Arithmetic</span></h3>
<p>A matrix times a constant results in a matrix where each element has been multiplied by that constant, e.g.,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mn>2</m:mn><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>8</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>For matrix multiplication, we “multiply” rows of the first matrix with columns of the second matrix:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>+</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>For matrix multiplication, we “multiply” rows of the first matrix with columns of the second matrix:</p>
<div class="disp-formula">
<m:math display="block"><m:mrow><m:mrow><m:mo>[</m:mo><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mn>1</m:mn><m:mi>m</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mi>i</m:mi><m:mn>1</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mi>i</m:mi><m:mi>m</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mi>r</m:mi><m:mn>1</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>a</m:mi><m:mrow><m:mi>r</m:mi><m:mi>m</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mi>m</m:mi><m:mn>1</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mn>1</m:mn><m:mi>j</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mi>m</m:mi><m:mi>j</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd><m:mtd><m:mrow><m:mtable><m:mtr><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mn>1</m:mn><m:mi>c</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>b</m:mi><m:mrow><m:mi>m</m:mi><m:mi>c</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mn>1</m:mn><m:mi>j</m:mi></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mn>1</m:mn><m:mi>c</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>i</m:mi><m:mn>1</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>i</m:mi><m:mi>j</m:mi></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>i</m:mi><m:mi>c</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mrow/></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>r</m:mi><m:mn>1</m:mn></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>r</m:mi><m:mi>j</m:mi></m:mrow></m:msub></m:mrow></m:mtd><m:mtd><m:mo>…</m:mo></m:mtd><m:mtd><m:mrow><m:msub><m:mi>p</m:mi><m:mrow><m:mi>r</m:mi><m:mi>c</m:mi></m:mrow></m:msub></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow><m:mo>]</m:mo></m:mrow><m:mo>.</m:mo></m:mrow></m:math>
</div>
<p>So the element <em>p<sub>ij</sub></em> of the resulting product is</p>
<div class="disp-formula" id="equ6_2">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mi>p</m:mi></m:mrow><m:mrow><m:mi>i</m:mi><m:mi>j</m:mi></m:mrow></m:msub><m:mo>=</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>i</m:mi><m:mn>1</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mn>1</m:mn><m:mi>j</m:mi></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>i</m:mi><m:mn>2</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mn>2</m:mn><m:mi>j</m:mi></m:mrow></m:msub><m:mo>+</m:mo><m:mn>...</m:mn><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>i</m:mi><m:mi>m</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>b</m:mi></m:mrow><m:mrow><m:mi>m</m:mi><m:mi>j</m:mi></m:mrow></m:msub><m:mn>.</m:mn></m:mrow><m:mspace width="3em"/><m:mo>(6.2)</m:mo></m:math>
</div>
<p>Taking a product of two matrices is only possible if the number of columns of the left matrix is the same as the number of rows of the right matrix. For example,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>8</m:mn></m:mtd><m:mtd><m:mn>9</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>12</m:mn></m:mtd><m:mtd><m:mn>17</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>22</m:mn></m:mtd><m:mtd><m:mn>27</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>24</m:mn></m:mtd><m:mtd><m:mn>33</m:mn></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>42</m:mn></m:mtd><m:mtd><m:mn>51</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>Matrix multiplication is <em>not</em> commutative in most instances:</p>
<div class="disp-formula" id="equ6_3">
<m:math alttext=""><m:mrow><m:mtext>AB</m:mtext><m:mo>≠</m:mo><m:mtext>BA.</m:mtext></m:mrow><m:mspace width="3em"/><m:mo>(6.3)</m:mo></m:math>
</div>
<p><a id="term-518"/><a id="term-519"/><span aria-label="111" epub:type="pagebreak" id="pg_111" role="doc-pagebreak"/>Also, if <strong>AB</strong> = <strong>AC</strong>, it does not necessarily follow that <strong>B</strong> = <strong>C</strong>. Fortunately, matrix multiplication is associative and distributive:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mstyle><m:mrow><m:mrow><m:mo>(</m:mo><m:mtext>AB</m:mtext><m:mo>)</m:mo><m:mtext>C</m:mtext></m:mrow></m:mrow></m:mstyle></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mtext>A</m:mtext><m:mrow><m:mo>(</m:mo><m:mtext>BC</m:mtext><m:mo>)</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>A</m:mtext><m:mrow><m:mo>(</m:mo><m:mtext>B+C</m:mtext><m:mo>)</m:mo></m:mrow></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mtext>AB</m:mtext><m:mo>+</m:mo><m:mrow><m:mtext>AC,</m:mtext></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:mo>(</m:mo><m:mtext>A+B</m:mtext><m:mo>)</m:mo><m:mtext>C</m:mtext></m:mrow></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mtext>AC+</m:mtext><m:mtext>BC.</m:mtext></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
</section>
<section>
<h3 id="sec6_2_2"><a id="index_term720"/><span class="green">6.2.2 Operations on Matrices</span></h3>
<p>We would like a matrix analog of the inverse of a real number. We know the inverse of a real number <em>x</em> is 1<em>/x</em> and that the product of <em>x</em> and its inverse is 1. We need a matrix <strong>I</strong> that we can think of as a “matrix one.” This exists only for square matrices and is known as the <em>identity matrix</em>; it consists of ones down the <em>diagonal</em> and zeroes elsewhere. For example, the four by four <a id="index_term717"/>identity matrix is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>I</m:mtext><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>The <em><a id="index_term718"/>inverse matrix</em> <strong>A</strong><sup>–1</sup> of a matrix <strong>A</strong> is the matrix that ensures <strong>AA</strong><sup>–</sup> 1 = <strong>I</strong>. For example,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:msup><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mo>=</m:mo><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>2.0</m:mn></m:mtd><m:mtd><m:mn>1.0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1.5</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>0.5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mtd><m:mtd><m:mtext>because</m:mtext><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr></m:mtable><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>2.0</m:mn></m:mtd><m:mtd><m:mn>1.0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1.5</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>0.5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>Note that the inverse of <strong>A</strong><sup>-1</sup> is <strong>A</strong>. So <strong>AA</strong><sup>-1</sup> = <strong>A</strong><sup>-1</sup><strong>A</strong> = <strong>I</strong>. The inverse of a product of two matrices is the product of the inverses, but with the order reversed:</p>
<div class="disp-formula" id="equ6_4">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mo>(</m:mo><m:mtext>AB</m:mtext><m:mo>)</m:mo></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>B</m:mtext></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:msup><m:mrow><m:mtext>A</m:mtext></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mn>.</m:mn></m:mrow><m:mspace width="3em"/><m:mo>(6.4)</m:mo></m:math>
</div>
<p>We will return to the question of computing inverses in <a href="C11_chapter6.xhtml#sec6_3">Section 6.3</a>.</p>
<p>The <em><a id="index_term724"/>transpose</em> <strong>A</strong><sup>T</sup> of a matrix <strong>A</strong> has the same numbers, but the rows are switched with the columns. If we label the entries of <strong>A</strong><sup>T</sup> as <em>a<sup/><sub>ij</sub></em>,then</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>i</m:mi><m:mi>j</m:mi></m:mrow></m:msub><m:mo>=</m:mo><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mi>j</m:mi><m:mi>i</m:mi></m:mrow><m:mrow><m:mo>′</m:mo></m:mrow></m:msubsup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>For example,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mn>6</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:math>
</div>
<p><span aria-label="112" epub:type="pagebreak" id="pg_112" role="doc-pagebreak"/>The transpose of a product of two matrices obeys a rule similar to Equation (6.4):</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mo>(</m:mo><m:mtext>AB</m:mtext><m:mo>)</m:mo></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>B</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:msup><m:mrow><m:mtext>A</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>The <a id="index_term713"/>determinant of a square matrix is simply the determinant of the columns of the matrix, considered as a set of vectors. The determinant has several nice relationships to the matrix operations just discussed, which we list here for reference:</p>
<div class="disp-formula" id="equ6_5">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>AB</m:mtext><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>B</m:mtext><m:mo>|</m:mo><m:mo>,</m:mo></m:mrow></m:mrow></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.5)</m:mo></m:math>
</div>
<div class="disp-formula" id="equ6_6">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:msup><m:mrow><m:mtext>A</m:mtext></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mo>|</m:mo><m:mo>=</m:mo><m:mfrac><m:mrow><m:mn>1</m:mn></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mo>,</m:mo></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.6)</m:mo></m:math>
</div>
<div class="disp-formula" id="equ6_7">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:msup><m:mrow><m:mtext>A</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.7)</m:mo></m:math>
</div>
</section>
<section>
<h3 id="sec6_2_3"><a id="index_term726"/><span class="green">6.2.3 Vector Operations in Matrix Form</span></h3>
<p>In graphics, we use a square matrix to transform a vector represented as a matrix. For example, if you have a 2D vector <strong>a</strong> = (<em>x<sub>a</sub></em>, <em>y<sub>a</sub></em>) and want to rotate it by 90 degrees about the origin to form vector <strong>a</strong> = (–<em>y<sub>a</sub></em>, <em>x<sub>a</sub></em>) , you can use a product of a 2 × 2 matrix and a 2 × 1 matrix, called a <em>column vector</em>. The operation in matrix form is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo></m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mo>−</m:mo><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>We can get the same result by using the transpose of this matrix and multiplying on the left (“premultiplying”) with a row vector:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mo>−</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>These days, postmultiplication using column vectors is fairly standard, but in many older books and systems, you will run across row vectors and premultiplication. The only difference is that the transform matrix must be replaced with its transpose.</p>
<p>We also can use matrix formalism to encode operations on just vectors. If we consider the result of the dot product as a 1 × 1 matrix, it can be written</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>a</m:mtext><m:mo>·</m:mo><m:mtext>b</m:mtext><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>a</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mtext>b.</m:mtext></m:mrow></m:math>
</div>
<p>For example, if we take two 3D vectors we get</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p><span aria-label="113" epub:type="pagebreak" id="pg_113" role="doc-pagebreak"/>A related vector product is the <em>outer product</em> between two vectors, which can be expressed as a matrix multiplication with a column vector on the left and a row vector on the right: <strong>ab</strong><sup>T</sup>. The result is a matrix consisting of products of all pairs of an entry of <strong>a</strong> with an entry of <strong>b</strong>. For 3D vectors, we have</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>a</m:mi></m:mrow></m:msub><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mi>b</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>It is often useful to think of matrix multiplication in terms of vector operations. To illustrate using the three-dimensional case, we can think of a 3 × 3 matrix as a collection of three 3D vectors in two ways: either it is made up of three column vectors side-by-side or it is made up of three row vectors stacked up. For instance, the result of a matrix-vector multiplication <strong>y</strong> = <strong>Ax</strong> can be interpreted as a vector whose entries are the dot products of <strong>x</strong> with the rows of <strong>A</strong>. Naming these row vectors <strong>r</strong><em><sub>i</sub></em>, we have</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>y</m:mtext></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mo>−</m:mo><m:msub><m:mrow><m:mtext>r</m:mtext></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub><m:mo>−</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:msub><m:mrow><m:mtext>r</m:mtext></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub><m:mo>−</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:msub><m:mrow><m:mtext>r</m:mtext></m:mrow><m:mrow><m:mn>3</m:mn></m:mrow></m:msub><m:mo>−</m:mo></m:mtd></m:mtr><m:mtr><m:mtd/></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd/></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>x</m:mtext></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>;</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mi>i</m:mi></m:mrow></m:msub><m:mo>=</m:mo><m:msub><m:mrow><m:mi>r</m:mi></m:mrow><m:mrow><m:mi>i</m:mi></m:mrow></m:msub><m:mo>·</m:mo><m:mtext>x</m:mtext><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>Alternatively, we can think of the same product as a sum of the three columns <strong>c</strong><em><sub>i</sub></em> of A, weighted by the entries of <strong>x</strong>:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>y</m:mtext></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd><m:mtd><m:mo>|</m:mo></m:mtd><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>c1</m:mtext></m:mtd><m:mtd><m:mtext>c2</m:mtext></m:mtd><m:mtd><m:mtext>c3</m:mtext></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>|</m:mo></m:mtd><m:mtd><m:mo>|</m:mo></m:mtd><m:mtd><m:mo>|</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>3</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>;</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mtext>y</m:mtext><m:mo>=</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mtext>c</m:mtext></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mtext>c</m:mtext></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>3</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mtext>c</m:mtext></m:mrow><m:mrow><m:mn>3</m:mn></m:mrow></m:msub><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>Using the same ideas, one can understand a matrix–matrix product <strong>AB</strong> as an array containing the pairwise dot products of all rows of <strong>A</strong> with all columns of <strong>B</strong> (cf. (6.2)); as a collection of products of the matrix <strong>A</strong> with all the column vectors of <strong>B</strong>, arranged left to right; as a collection of products of all the row vectors of <strong>A</strong> with the matrix <strong>B</strong>, stacked top to bottom; or as the sum of the pairwise outer products of all columns of <strong>A</strong> with all rows of <strong>B</strong>. (See Exercise 8.)</p>
<p>These interpretations of matrix multiplication can often lead to valuable geometric interpretations of operations that may otherwise seem very abstract.</p>
</section>
<section>
<h3 id="sec6_2_4"><a id="index_term725"/><span class="green">6.2.4 Special Types of Matrices</span></h3>
<p>The identity matrix is an example of a <em><a id="index_term715"/>diagonal matrix</em>, where all nonzero elements occur along the diagonal. The diagonal consists of those elements whose column index equals the row index counting from the upper left.</p>
<p><a id="term-521"/><a id="term-572"/><span aria-label="114" epub:type="pagebreak" id="pg_114" role="doc-pagebreak"/>The identity matrix also has the property that it is the same as its transpose. Such matrices are called <em>symmetric</em>.</p>
<p>The identity matrix is also an <em>orthogonal</em> matrix, because each of its columns considered as a vector has length 1 and the columns are orthogonal to one another. The same is true of the rows (see Exercise 2). The determinant of any orthogonal matrix is either +1 or <em>–</em>1.</p>
<aside class="boxed-text" epub:type="sidebar">
<p class="noindent">The idea of an orthogonal matrix corresponds to the idea of an <em>orthonormal</em> basis, not just a set of <em>orthogonal</em> vectors—an unfortunate glitch in terminology.</p>
</aside>
<p class="indent">A very useful property of orthogonal matrices is that they are nearly their own inverses. Multiplying an <a id="index_term807"/>orthogonal matrix by its transpose results in the identity,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:msup><m:mrow><m:mtext>R</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mtext>R</m:mtext><m:mo>=</m:mo><m:mi>I</m:mi><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>RR</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup></m:mtd><m:mtd><m:mtext>for orthogonal</m:mtext><m:mtext>R.</m:mtext></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>This is easy to see because the entries of <strong>R</strong><sup>T</sup><strong>R</strong> are dot products between the columns of <strong>R</strong>. Off-diagonal entries are dot products between orthogonal vectors, and the diagonal entries are dot products of the (unit-length) columns with themselves.</p>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 3</span> The matrix</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>8</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>9</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:math>
</div>
<p>is diagonal, and therefore symmetric, but not orthogonal (the columns are orthogonal but they are not unit length).</p>
<p>The matrix</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>9</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:math>
</div>
<p>is symmetric, but not diagonal or orthogonal.</p>
<p>The matrix</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:math>
</div>
<p>is orthogonal, but neither diagonal nor symmetric.</p>
</aside>
</section>
</section>
<section>
<h2 id="sec6_3"><a id="index_term712"/><a epub:type="backlink" href="C02a_toc.xhtml#rsec6_3" role="doc-backlink"><span class="green">6.3 Computing with Matrices and Determinants</span></a></h2>
<p>Recall from <a href="C11_chapter6.xhtml#sec6_1">Section 6.1</a> that the determinant takes <em>n n</em>-dimensional vectors and combines them to get a signed <em>n</em>-dimensional volume of the <em>n</em>-dimensional parallelepiped defined by the vectors. For example, the determinant in 2D is the area <a id="term-517"/><a id="term-584"/><span aria-label="115" epub:type="pagebreak" id="pg_115" role="doc-pagebreak"/>of the <a id="index_term820"/>parallelogram formed by the vectors. We can use matrices to handle the mechanics of computing determinants.</p>
<p>If we have 2D vectors <strong>r</strong> and <strong>s</strong>, we denote the determinant |<strong>rs</strong>|; this value is the signed area of the parallelogram formed by the vectors. Suppose we have two 2D vectors with Cartesian coordinates (<em>a, b</em>) and (<em>A, B</em>) (<a href="C11_chapter6.xhtml#f6_7">Figure 6.7</a>). The determinant can be written in terms of column vectors or as a shorthand:</p>
<div class="disp-formula" id="equ6_8">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mo>|</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mi>a</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>b</m:mi></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mi>A</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>B</m:mi></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr></m:mtable><m:mo>≡</m:mo><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mi>a</m:mi></m:mtd><m:mtd><m:mi>A</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>b</m:mi></m:mtd><m:mtd><m:mi>B</m:mi></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>=</m:mo><m:mi>a</m:mi><m:mi>B</m:mi><m:mo>−</m:mo><m:mi>A</m:mi><m:mi>b</m:mi><m:mn>.</m:mn></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.8)</m:mo></m:math>
</div>
<p>Note that the determinant of a matrix is the same as the determinant of its transpose:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mi>a</m:mi></m:mtd><m:mtd><m:mi>A</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>b</m:mi></m:mtd><m:mtd><m:mi>B</m:mi></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>=</m:mo><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mi>a</m:mi></m:mtd><m:mtd><m:mi>b</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>A</m:mi></m:mtd><m:mtd><m:mi>B</m:mi></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>=</m:mo><m:mi>a</m:mi><m:mi>B</m:mi><m:mo>−</m:mo><m:mi>A</m:mi><m:mi>b</m:mi><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:math>
</div>
<figure id="f6_7" tabindex="0">
<img alt="" src="../images/fig6_7.jpg"/>
<figcaption><p><span class="blue">Figure 6.7.</span> The 2D determinant in Equation 6.8 is the area of the parallelogram formed by the 2D vectors.</p></figcaption>
</figure>
<p class="noindent1">This means that for any parallelogram in 2D, there is a “sibling” parallelogram that has the same area but a different shape (<a href="C11_chapter6.xhtml#f6_8">Figure 6.8</a>). For example, the parallelogram defined by vectors (3, 1) and (2, 4) has area 10, as does the parallelogram defined by vectors (3, 2) and (1, 4) .</p>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 4</span> The geometric meaning of the 3D determinant is helpful in seeing why certain formulas make sense. For example, the equation of the plane through the points (<em>x<sub>i</sub></em>, <em>y<sub>i</sub></em>, <em>z<sub>i</sub></em>) for <em>i</em> = 0, 1, 2 is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mi>x</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>0</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mi>x</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mi>x</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mi>y</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>0</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mi>y</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mi>y</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mi>z</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mn>0</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mi>z</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mi>z</m:mi><m:mo>−</m:mo><m:msub><m:mrow><m:mi>z</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mn>0.</m:mn></m:mrow></m:math>
</div>
<figure id="f6_8" tabindex="0">
<img alt="" src="../images/fig6_8.jpg"/>
<figcaption><p><span class="blue">Figure 6.8.</span> The sibling parallelogram has the same area as the parallelogram in <a href="C11_chapter6.xhtml#f6_7">Figure 6.7</a>.</p></figcaption>
</figure>
<p class="noindent1">Each column is a vector from point (<em>x<sub>i</sub> ,y<sub>i</sub> ,z<sub>i</sub></em>) to point (<em>x, y, z</em>) . The volume of the parallelepiped with those vectors as sides is zero only if (<em>x, y, z</em>) is coplanar with the three other points. Almost all equations involving determinants have similarly simple underlying geometry.</p>
</aside>
<p class="indentt">As we saw earlier, we can compute determinants by a brute force expansion where most terms are zero, and there is a great deal of bookkeeping on plus and minus signs. The standard way to manage the algebra of computing determinants is to use a form of <em><a id="index_term658"/>Laplace’s expansion</em>. The key part of computing the determinant this way is to find <em><a id="index_term711"/>cofactors</em> of various matrix elements. Each element of a square matrix has a cofactor which is the determinant of a matrix with one fewer row and column possibly multiplied by minus one. The smaller matrix is obtained by eliminating the row and column that the element in question is in. For example, for a 10 × 10 matrix, the cofactor of <em>a</em><sub>82</sub> is the determinant of the 9 × 9 matrix with the 8th row and 2nd column eliminated. The sign of a cofactor is positive if <span aria-label="116" epub:type="pagebreak" id="pg_116" role="doc-pagebreak"/>the sum of the row and column indices is even and negative otherwise. This can be remembered by a checkerboard pattern:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mn>...</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mn>...</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mn>...</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mo>−</m:mo></m:mtd><m:mtd><m:mo>+</m:mo></m:mtd><m:mtd><m:mn>...</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd><m:mtd><m:mo>⋮</m:mo></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:math>
</div>
<p>So, for a 4 × 4 matrix,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>A</m:mtext><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>41</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:math>
</div>
<p>The cofactors of the first row are</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>,</m:mo></m:mrow></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>=</m:mo><m:mo>−</m:mo><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>41</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>,</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>=</m:mo><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>,</m:mo></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>=</m:mo><m:mo>−</m:mo><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>41</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/></m:mtr><m:mtr><m:mtd/><m:mtd/></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>The determinant of a matrix is found by taking the sum of products of the elements of any row or column with their cofactors. For example, the determinant of the 4 × 4 matrix above taken about its second column is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo><m:mo>=</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mn>.</m:mn></m:mrow></m:mrow></m:math>
</div>
<p>We could do a similar expansion about any row or column and they would all yield the same result. Note the recursive nature of this expansion.</p>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 5</span> A concrete example for the determinant of a particular 3 × 3 matrix by expanding the cofactors of the first row is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>8</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:mn>0</m:mn><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>4</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>8</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>−</m:mo><m:mn>1</m:mn><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd><m:mtd><m:mn>8</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>+</m:mo><m:mn>2</m:mn><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>6</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:mn>0</m:mn><m:mrow><m:mo>(</m:mo><m:mn>32</m:mn><m:mo>−</m:mo><m:mn>35</m:mn><m:mo>)</m:mo><m:mo>−</m:mo><m:mn>1</m:mn><m:mrow><m:mo>(</m:mo><m:mn>24</m:mn><m:mo>−</m:mo><m:mn>30</m:mn><m:mo>)</m:mo><m:mo>+</m:mo><m:mn>2</m:mn><m:mrow><m:mo>(</m:mo><m:mn>21</m:mn><m:mo>−</m:mo><m:mn>24</m:mn><m:mo>)</m:mo></m:mrow></m:mrow></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd columnalign="left"><m:mn>0.</m:mn></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p><a id="term-480"/><a id="term-516"/><a id="term-520"/><span aria-label="117" epub:type="pagebreak" id="pg_117" role="doc-pagebreak"/>We can deduce that the volume of the parallelepiped formed by the vectors defined by the columns (or rows since the determinant of the transpose is the same) is zero. This is equivalent to saying that the columns (or rows) are not linearly independent. Note that the sum of the first and third rows is twice the second row, which implies linear dependence.</p>
</aside>
<section>
<h3 id="sec6_3_1"><a id="index_term681"/><span class="green">6.3.1 Computing Inverses</span></h3>
<p>Determinants give us a tool to compute the inverse of a matrix. It is a very inefficient method for large matrices, but often in graphics, our matrices are small. A key to developing this method is that the determinant of a matrix with two identical rows is zero. This should be clear because the volume of the <em>n</em>-dimensional parallelepiped is zero if two of its sides are the same. Suppose we have a 4 × 4 <strong>A</strong> and we wish to find its inverse <strong>A</strong><sup>–1</sup>. The inverse is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mtext>A</m:mtext></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:mo>=</m:mo><m:mfrac><m:mrow><m:mn>1</m:mn></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>41</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd><m:mtd><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>Note that this is just the transpose of the matrix where elements of <strong>A</strong> are replaced by their respective cofactors multiplied by the leading constant (1 or <em>–</em>1). This matrix is called the <em>adjoint</em> of <strong>A</strong>. The adjoint is the transpose of the <em>cofactor</em> matrix of <strong>A</strong>. We can see why this is an inverse. Look at the product <strong>AA</strong><sup>–1</sup> which we expect to be the identity. If we multiply the first row of <strong>A</strong> by the first column of the adjoint matrix we need to get |<strong>A</strong>| (remember the leading constant above divides by |<strong>A</strong>|:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>|</m:mo><m:mtext>A</m:mtext><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>This is true because the elements in the first row of <strong>A</strong> are multiplied exactly by their cofactors in the first column of the <a id="index_term709"/>adjoint matrix which is exactly the determinant. The other values along the diagonal of the resulting matrix are |<strong>A</strong><em>|</em> for analogous reasons. The zeros follow a similar logic:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd><m:mtd><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p><a id="term-509"/><span aria-label="118" epub:type="pagebreak" id="pg_118" role="doc-pagebreak"/>Note that this product is a determinant of <em>some</em> matrix:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>13</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub><m:msubsup><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>14</m:mn></m:mrow><m:mrow><m:mi>c</m:mi></m:mrow></m:msubsup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>The matrix in fact is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>23</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>24</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>31</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>32</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>33</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>34</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>41</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>42</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>43</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>44</m:mn></m:mrow></m:msub><m:mn>.</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>Because the first two rows are identical, the matrix is singular, and thus, its determinant is zero.</p>
<p>The argument above does not apply just to four by four matrices; using that size just simplifies typography. For any matrix, the inverse is the adjoint matrix divided by the determinant of the matrix being inverted. The adjoint is the transpose of the cofactor matrix, which is just the matrix whose elements have been replaced by their cofactors.</p>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 6</span> The inverse of one particular three-by-three matrix whose determinant is 6 is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:msup><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup></m:mtd><m:mtd><m:mo>=</m:mo><m:mfrac><m:mrow><m:mn>1</m:mn></m:mrow><m:mrow><m:mn>6</m:mn></m:mrow></m:mfrac><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mo>−</m:mo><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:mo>−</m:mo><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mo>−</m:mo><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mo>−</m:mo><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd><m:mtd><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>3</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mfrac><m:mrow><m:mn>1</m:mn></m:mrow><m:mrow><m:mn>6</m:mn></m:mrow></m:mfrac><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mn>.</m:mn></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd/></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>You can check this yourself by multiplying the matrices and making sure you get the identity.</p>
</aside>
</section>
<section>
<h3 id="sec6_3_2"><a id="index_term694"/><span class="green">6.3.2 Linear Systems</span></h3>
<p>We often encounter linear systems in graphics with “<em>n</em> equations and <em>n</em> unknowns,” usually for <em>n</em> = 2 or <em>n</em> = 3. For example,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable columnalign="left"><m:mtr><m:mtd><m:mn>3</m:mn><m:mi>x</m:mi><m:mo>+</m:mo><m:mn>7</m:mn><m:mi>y</m:mi><m:mo>+</m:mo><m:mn>2</m:mn><m:mi>z</m:mi><m:mo>=</m:mo><m:mn>4</m:mn><m:mo>,</m:mo></m:mtd></m:mtr><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn><m:mi>x</m:mi><m:mo>−</m:mo><m:mn>4</m:mn><m:mi>y</m:mi><m:mo>−</m:mo><m:mn>3</m:mn><m:mi>z</m:mi><m:mo>=</m:mo><m:mo>−</m:mo><m:mn>1</m:mn><m:mo>,</m:mo></m:mtd></m:mtr><m:mtr><m:mtd columnalign="left"><m:mn>5</m:mn><m:mi>x</m:mi><m:mo>+</m:mo><m:mn>2</m:mn><m:mi>y</m:mi><m:mo>+</m:mo><m:mi>z</m:mi><m:mo>=</m:mo><m:mn>1.</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p><a id="term-505"/><a id="term-506"/><span aria-label="119" epub:type="pagebreak" id="pg_119" role="doc-pagebreak"/>Here, <em>x</em>, <em>y</em>, and <em>z</em> are the “unknowns” for which we wish to solve. We can write this in matrix form:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mi>x</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>y</m:mi></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>z</m:mi></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mtable><m:mtr><m:mtd><m:mn>4</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>A common shorthand for such systems is <strong>Ax</strong> = <strong>b</strong> where it is assumed that <strong>A</strong> is a square matrix with known constants, <strong>x</strong> is an unknown column vector (with elements <em>x</em>, <em>y</em>,and <em>z</em> in our example), and <strong>b</strong> is a column matrix of known constants.</p>
<p>There are many ways to solve such systems, and the appropriate method depends on the properties and dimensions of the matrix <strong>A</strong>. Because in graphics we so frequently work with systems of size <em>n</em> ≤ 4, we’ll discuss here a method appropriate for these systems, known as <em><a id="index_term276"/>Cramer’s rule</em>, which we saw earlier, from a 2D geometric viewpoint, in the example on page 108. Here, we show this algebraically. The solution to the above equation is</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mi>x</m:mi><m:mo>=</m:mo><m:mfrac><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>4</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mo>;</m:mo><m:mi>y</m:mi><m:mo>=</m:mo><m:mfrac><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>4</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mo>;</m:mo><m:mi>z</m:mi><m:mo>=</m:mo><m:mfrac><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:mn>3</m:mn></m:mtd><m:mtd><m:mn>7</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>4</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>3</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>5</m:mn></m:mtd><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow></m:mrow></m:mfrac><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>The rule here is to take a ratio of determinants, where the denominator is |<strong>A</strong>| and the numerator is the determinant of a matrix created by replacing a column of <strong>A</strong> with the column vector <strong>b</strong>. The column replaced corresponds to the position of the unknown in vector <strong>x</strong>. For example, <em>y</em> is the second unknown and the second column is replaced. Note that if |<strong>A</strong>| = 0, the division is undefined and there is no solution. This is just another version of the rule that if <strong>A</strong> is singular (zero determinant), then there is no unique solution to the equations.</p>
</section>
</section>
<section>
<h2 id="sec6_4"><a id="index_term683"/><a id="index_term687"/><a id="index_term716"/><a epub:type="backlink" href="C02a_toc.xhtml#rsec6_4" role="doc-backlink"><span class="green">6.4 Eigenvalues and Matrix Diagonalization</span></a></h2>
<p>Square matrices have <em>eigenvalues</em> and <em><a id="index_term684"/>eigenvectors</em> associated with them. The eigenvectors are those <em>nonzero</em> vectors whose directions do not change when multiplied by the matrix. For example, suppose for a matrix <strong>A</strong> and vector <strong>a</strong>,wehave</p>
<div class="disp-formula" id="equ6_9">
<m:math alttext=""><m:mrow><m:mtext>Aa</m:mtext><m:mo>=</m:mo><m:mi>λ</m:mi><m:mtext>a.</m:mtext></m:mrow><m:mspace width="3em"/><m:mo>(6.9)</m:mo></m:math>
</div>
<p>This means we have stretched or compressed <strong>a</strong>, but its direction has not changed. The scale factor λ is called the eigenvalue associated with eigenvector <strong>a</strong>. Knowing <span aria-label="120" epub:type="pagebreak" id="pg_120" role="doc-pagebreak"/>the eigenvalues and eigenvectors of matrices is helpful in a variety of practical applications. We will describe them to gain insight into geometric transformation matrices and as a step toward singular values and vectors described in the next section.</p>
<p>If we assume a matrix has at least one eigenvector, then we can do a standard manipulation to find it. First, we write both sides as the product of a square matrix with the vector <strong>a</strong>:</p>
<div class="disp-formula" id="equ6_10">
<m:math alttext=""><m:mrow><m:mtext>Aa</m:mtext><m:mo>=</m:mo><m:mi>λ</m:mi><m:mtext>Ia,</m:mtext></m:mrow><m:mspace width="3em"/><m:mo>(6.10)</m:mo></m:math>
</div>
<p>where <strong>I</strong> is an identity matrix. This can be rewritten</p>
<div class="disp-formula" id="equ6_11">
<m:math alttext=""><m:mrow><m:mtext>Aa</m:mtext><m:mo>−</m:mo><m:mi>λ</m:mi><m:mtext>Ia</m:mtext><m:mo>=</m:mo><m:mn>0.</m:mn></m:mrow><m:mspace width="3em"/><m:mo>(6.11)</m:mo></m:math>
</div>
<p>Because matrix multiplication is distributive, we can group the matrices:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>(</m:mo><m:mtext>A</m:mtext><m:mo>−</m:mo><m:mi>λ</m:mi><m:mtext>I</m:mtext><m:mo>)</m:mo><m:mtext>a</m:mtext><m:mo>=</m:mo><m:mn>0.</m:mn></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.12)</m:mo></m:math>
</div>
<p>This equation can only be true if the matrix (<strong>A</strong> <em>–λ</em><strong>I</strong>) is singular, and thus, its determinant is zero. The elements in this matrix are the numbers in <strong>A</strong> except along the diagonal. For example, for a 2 × 2 matrix the eigenvalues obey</p>
<div class="disp-formula" id="equ6_13">
<m:math alttext=""><m:mrow><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub><m:mo>−</m:mo><m:mi>λ</m:mi></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn><m:mo>−</m:mo><m:mi>λ</m:mi></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo><m:mo>=</m:mo><m:msup><m:mrow><m:mi>λ</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msup><m:mo>−</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub><m:mo>+</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub><m:mo>)</m:mo><m:mi>λ</m:mi><m:mo>+</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>11</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>22</m:mn></m:mrow></m:msub><m:mo>−</m:mo><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>12</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mi>a</m:mi></m:mrow><m:mrow><m:mn>21</m:mn></m:mrow></m:msub><m:mo>)</m:mo><m:mo>=</m:mo><m:mn>0.</m:mn></m:mrow></m:mrow></m:mrow></m:mrow><m:mspace width="3em"/><m:mo>(6.13)</m:mo></m:math>
</div>
<p>Because this is a quadratic equation, we know there are exactly two solutions for λ. These solutions may or may not be unique or real. A similar manipulation for an <em>n</em> × <em>n</em> matrix will yield an <em>n</em>th-degree polynomial in λ. Because it is not possible, in general, to find exact explicit solutions of polynomial equations of degree greater than four, we can only compute eigenvalues of matrices 4 × 4 or smaller by analytic methods. For larger matrices, numerical methods are the only option.</p>
<p>An important special case where eigenvalues and eigenvectors are particularly simple is symmetric matrices (where <strong>A</strong> = <strong>A</strong><sup>T</sup>). The eigenvalues of real symmetric matrices are always real numbers, and if they are also distinct, their eigenvectors are mutually orthogonal. Such matrices can be put into <em>diagonal form</em>:</p>
<div class="disp-formula" id="equ6_14">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mtext>A</m:mtext><m:mo>=</m:mo><m:mtext>QDQ</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>,</m:mo></m:mrow><m:mspace width="3em"/><m:mo>(6.14)</m:mo></m:math>
</div>
<p>where <strong>Q</strong> is an orthogonal matrix and <strong>D</strong> is a diagonal matrix. The columns of <strong>Q</strong> are the eigenvectors of <strong>A</strong> and the diagonal elements of <strong>D</strong> are the eigenvalues of <strong>A</strong>. Putting <strong>A</strong> in this form is also called the <em>eigenvalue decomposition</em>, because it decomposes <strong>A</strong> into a product of simpler matrices that reveal its eigenvectors and eigenvalues.</p>
<aside class="boxed-text" epub:type="sidebar">
<p class="noindent">Recall that an <em>orthogonal</em> matrix has <em>orthonormal</em> rows and <em>orthonormal</em> columns.</p>
</aside>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue"><span aria-label="121" epub:type="pagebreak" id="pg_121" role="doc-pagebreak"/>Example 7</span> Given the matrix</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>A</m:mtext><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>,</m:mo></m:mrow></m:mrow></m:math>
</div>
<p>the eigenvalues of <strong>A</strong> are the solutions to</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mi>λ</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msup><m:mo>−</m:mo><m:mn>3</m:mn><m:mi>λ</m:mi><m:mo>+</m:mo><m:mn>1</m:mn><m:mo>=</m:mo><m:mn>0.</m:mn></m:mrow></m:math>
</div>
<p>We approximate the exact values for compactness of notation:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mi>λ</m:mi><m:mo>=</m:mo><m:mfrac><m:mrow><m:mn>3</m:mn><m:mo>±</m:mo><m:msqrt><m:mrow><m:mn>5</m:mn></m:mrow></m:msqrt></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:mfrac><m:mo>,</m:mo><m:mo>≈</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2.618</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0.382</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:math>
</div>
<p>Now we can find the associated eigenvector. The first is the nontrivial (not <em>x</em> = <em>y</em> = 0) solution to the homogeneous equation,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn><m:mo>−</m:mo><m:mn>2.618</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn><m:mo>−</m:mo><m:mn>2.618</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mi>x</m:mi></m:mtd></m:mtr><m:mtr><m:mtd><m:mi>y</m:mi></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>This is approximately (<em>x, y</em>) = (0.8507, 0.5257) . Note that there are infinitely many solutions parallel to that 2D vector, and we just picked the one of unit length. Similarly, the eigenvector associated with λ<sub>2</sub> is (<em>x, y</em>) = (<em>–</em>0.5257, 0.8507) .This means the diagonal form of <strong>A</strong> is (within some precision due to our numeric approximation):</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0.8507</m:mn></m:mtd><m:mtd columnalign="right"><m:mo>−</m:mo><m:mn>0.5257</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0.5257</m:mn></m:mtd><m:mtd columnalign="right"><m:mn>0.8507</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2.618</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0.382</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0.8507</m:mn></m:mtd><m:mtd><m:mn>0.5207</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>0.5257</m:mn></m:mtd><m:mtd><m:mn>0.8507</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:math>
</div>
</aside>
<p class="noindent">We will revisit the geometry of this matrix as a transform in the next chapter.</p>
<section>
<h3 id="sec6_4_1"><a id="index_term1088"/><span class="green">6.4.1 Singular Value Decomposition</span></h3>
<p>We saw in the last section that any symmetric matrix can be diagonalized, or decomposed into a convenient product of orthogonal and diagonal matrices. However, most matrices we encounter in graphics are not symmetric, and the eigenvalue decomposition for nonsymmetric matrices is not nearly so convenient or illuminating, and in general involves complex-valued eigenvalues and eigenvectors even for real-valued inputs.</p>
<aside class="boxed-text" epub:type="sidebar">
<p class="noindent">We would recommend learning in this order: symmetric eigenvalues/vectors, singular values/vectors, and <em>then</em> nonsymmetric eigenvalues, which are much trickier.</p>
</aside>
<p class="indent">There is another generalization of the symmetric eigenvalue decomposition to nonsymmetric (and even non-square) matrices; it is the <em>singular value decomposition</em> (SVD). The main difference between the eigenvalue decomposition of a symmetric matrix and the SVD of a nonsymmetric matrix is that the orthogonal matrices on the left and right sides are not required to be the same in the SVD:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mtext>A</m:mtext><m:mo>=</m:mo><m:mtext>USV</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p><span aria-label="122" epub:type="pagebreak" id="pg_122" role="doc-pagebreak"/>Here, <strong>U</strong> and <strong>V</strong> are two, potentially different, orthogonal matrices, whose columns are known as the left and right <em>singular vectors</em> of <strong>A</strong>,and <strong>S</strong> is a diagonal matrix whose entries are known as the <em>singular values</em> of <strong>A</strong>. When <strong>A</strong> is symmetric and has all nonnegative eigenvalues, the SVD and the eigenvalue decomposition are the same.</p>
<p>There is another relationship between singular values and eigenvalues that can be used to compute the SVD (though this is not the way an industrial-strength SVD implementation works). First, we define <strong>M</strong> = <strong>AA</strong><sup>T</sup>. We assume that we can perform a SVD on <strong>M</strong>:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mtext>M</m:mtext><m:mo>=</m:mo><m:mtext>AA</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:mrow><m:mo>(</m:mo><m:msup><m:mrow><m:mtext>USV</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>)</m:mo><m:msup><m:mrow><m:mo>(</m:mo><m:msup><m:mrow><m:mtext>USV</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>)</m:mo></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:mtext>US</m:mtext><m:mrow><m:mo>(</m:mo><m:msup><m:mrow><m:mtext>V</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mtext>V</m:mtext><m:mo>)</m:mo><m:msup><m:mrow><m:mtext>SU</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>US</m:mtext></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msup><m:msup><m:mrow><m:mtext>U</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>The substitution is based on the fact that (<strong>BC</strong>)<sup>T</sup> = <strong>C</strong><sup>T</sup><strong>B</strong><sup>T</sup>, that the transpose of an orthogonal matrix is its inverse, and that the transpose of a diagonal matrix is the matrix itself. The beauty of this new form is that <strong>M</strong> is symmetric and <strong>US</strong><sup>2</sup><strong>U</strong><sup>T</sup> is its eigenvalue decomposition, where <strong>S</strong><sup>2</sup> contains the (all nonnegative) eigenvalues. Thus, we find that the singular values of a matrix are the square roots of the eigenvalues of the product of the matrix with its transpose, and the left singular vectors are the eigenvectors of that product. A similar argument allows <strong>V</strong>, the matrix of right <a id="index_term1090"/>singular vectors, to be computed from <strong>A</strong><sup>T</sup><strong>A</strong>.</p>
<aside class="boxed-text-e" epub:type="sidebar">
<p class="noindent1"><span class="blue">Example 8</span> We now make this concrete with an example:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mtext>A</m:mtext><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>;</m:mo></m:mrow></m:mtd><m:mtd><m:mtext>M</m:mtext><m:mo>=</m:mo><m:msup><m:mrow><m:mtext>AA</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>2</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
<p>We saw the eigenvalue decomposition for this matrix in the previous section. We observe immediately</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mo>=</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0.8507</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>0.5257</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0.5257</m:mn></m:mtd><m:mtd><m:mn>0.8507</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msqrt><m:mrow><m:mn>2.618</m:mn></m:mrow></m:msqrt></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:msqrt><m:mrow><m:mn>0.382</m:mn></m:mrow></m:msqrt></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mrow></m:mrow><m:msup><m:mrow><m:mtext>V</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>We can solve for <strong>V</strong> algebraically:</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msup><m:mrow><m:mtext>V</m:mtext><m:mo>=</m:mo><m:mrow><m:mo>(</m:mo><m:msup><m:mrow><m:mtext>S</m:mtext></m:mrow><m:mrow><m:mo>−</m:mo><m:mn>1</m:mn></m:mrow></m:msup><m:msup><m:mrow><m:mtext>U</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mtext>A</m:mtext><m:mo>)</m:mo></m:mrow></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup><m:mn>.</m:mn></m:mrow></m:math>
</div>
<p>The inverse of <strong>S</strong> is a diagonal matrix with the reciprocals of the diagonal elements of <strong>S</strong>. This yields</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtable><m:mtr><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo></m:mrow></m:mtd><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mtext>U</m:mtext><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>σ</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:msub><m:mrow><m:mi>σ</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:msup><m:mrow><m:mtext>v</m:mtext></m:mrow><m:mrow><m:mtext>T</m:mtext></m:mrow></m:msup></m:mrow></m:mtd></m:mtr><m:mtr><m:mtd/><m:mtd><m:mo>=</m:mo></m:mtd><m:mtd><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0.8507</m:mn></m:mtd><m:mtd><m:mo>−</m:mo><m:mn>0.5257</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0.5257</m:mn></m:mtd><m:mtd><m:mn>0.8507</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>1.618</m:mn></m:mtd><m:mtd><m:mn>0</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>0</m:mn></m:mtd><m:mtd><m:mn>0.618</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mrow><m:mo>[</m:mo><m:mtable><m:mtr><m:mtd><m:mn>0.5207</m:mn></m:mtd><m:mtd><m:mn>0.8507</m:mn></m:mtd></m:mtr><m:mtr><m:mtd><m:mo>−</m:mo><m:mn>0.8507</m:mn></m:mtd><m:mtd><m:mn>0.5257</m:mn></m:mtd></m:mtr></m:mtable><m:mo>]</m:mo><m:mn>.</m:mn></m:mrow></m:mrow></m:mrow></m:mtd></m:mtr></m:mtable></m:mrow></m:math>
</div>
</aside>
<p class="indent"><span aria-label="123" epub:type="pagebreak" id="pg_123" role="doc-pagebreak"/>This form used the standard symbol <em>σ<sub>i</sub></em> for the <em>i</em>th singular value. Again, for a symmetric matrix, the eigenvalues and the singular values are the same (<em>σ<sub>i</sub></em> = <em>λ<sub>i</sub></em>). We will examine the geometry of SVD further in <a href="C12_chapter7.xhtml#sec7_1_6">Section 7.1.6</a>.</p>
</section>
</section>
<section>
<h2 id="sec24"><span class="green">Frequently Asked Questions</span></h2>
<ul class="list-bullet">
<li>
<p class="list"><span class="green">Why is matrix multiplication defined the way it is rather than just element by element?</span></p>
<p class="noindent1b">Element by element multiplication is a perfectly good way to define matrix multiplication, and indeed, it has nice properties. However, in practice it is not very useful. Ultimately, most matrices are used to transform column vectors; e.g., in 3D you might have</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mtext>b</m:mtext><m:mo>=</m:mo><m:mtext>Ma,</m:mtext></m:mrow></m:math>
</div>
<p>where <strong>a</strong> and <strong>b</strong> are vectors and <strong>M</strong> is a 3×3 matrix. To allow geometric operations such as rotation, combinations of all three elements of <strong>a</strong> must go into each element of <strong>b</strong>. That requires us to go either row-by-row or column-by-column through <strong>M</strong>. That choice is made based on composition of matrices having the desired property,</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:msub><m:mrow><m:mtext>M</m:mtext></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mtext>M</m:mtext></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub><m:mtext>a</m:mtext><m:mo>)</m:mo><m:mo>=</m:mo><m:mrow><m:mo>(</m:mo><m:msub><m:mrow><m:mtext>M</m:mtext></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub><m:msub><m:mrow><m:mtext>M</m:mtext></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub><m:mo>)</m:mo><m:mtext>a</m:mtext></m:mrow></m:mrow></m:mrow></m:math>
</div>
<p>which allows us to use one composite matrix <strong>C</strong> = <strong>M</strong><sub>2</sub><strong>M</strong><sub>1</sub> to transform our vector. This is valuable when many vectors will be transformed by the same composite matrix. So, in summary, the somewhat weird rule for matrix multiplication is engineered to have these desired properties.</p>
</li>
<li>
<p class="list"><span class="green">Sometimes I hear that eigenvalues and singular values are the same thing and sometimes that one is the square of the other. Which is right?</span></p>
<p class="noindent1b">If a real matrix <strong>A</strong> is symmetric, and its eigenvalues are nonnegative, then its eigenvalues and singular values are the same. If <strong>A</strong> is not symmetric, the matrix <strong>M</strong> = <strong>AA</strong><sup>T</sup> is symmetric and has nonnegative real eignenvalues. The singular values of <strong>A</strong> and <strong>A</strong><sup>T</sup> are the same and are the square roots of the singular/eigenvalues of <strong>M</strong>. Thus, when the square root statement is made, it is because two different matrices (with a very particular relationship) are being talked about: <strong>M</strong> = <strong>AA</strong><sup>T</sup>.</p>
</li>
</ul>
</section>
<section>
<h2 id="sec25"><span aria-label="124" epub:type="pagebreak" id="pg_124" role="doc-pagebreak"/><span class="green">Notes</span></h2>
<p>The discussion of determinants as volumes is based on <em>A Vector Space Approach to Geometry</em> (Hausner, 1998). <a id="index_term517"/>Hausner has an excellent discussion of vector analysis and the fundamentals of geometry as well. The geometric derivation of <a id="index_term277"/>Cramer’s rule in 2D is taken from <em>Practical Linear Algebra: A Geometry Tool-box</em> (Farin &amp; Hansford, 2004). That book also has geometric interpretations of other linear algebra operations such as Gaussian elimination. The discussion of eigenvalues and singular values is based primarily on <em>Linear Algebra and Its Applications</em> (Strang, 1988). The example of SVD of the shear matrix is based on a discussion in <em>Computer Graphics and Geometric Modeling</em> (Salomon, 1999).</p>
</section>
<section>
<h2 id="sec26"><span class="green">Exercises</span></h2>
<p class="qpara"><span class="green">1.</span> Write an implicit equation for the 2D line through points (<em>x</em><sub>0</sub><em>,y</em><sub>0</sub>) and (<em>x</em><sub>1</sub><em>,y</em><sub>1</sub>) using a 2D determinant.</p>
<p class="qpara"><span class="green">2.</span> Show that if the columns of a matrix are orthonormal, then so are the rows.</p>
<p class="qpara"><span class="green">3.</span> Prove the properties of matrix determinants stated in Equations (6.5)–(6.7).</p>
<p class="qpara"><span class="green">4.</span> Show that the eigenvalues of a diagonal matrix are its diagonal elements.</p>
<p class="qpara"><span class="green">5.</span> Show that for a square matrix <strong>A</strong>, <strong>AA</strong><sup>T</sup> is a symmetric matrix.</p>
<p class="qpara"><span class="green">6.</span> Show that for three 3D vectors <strong>a</strong>, <strong>b</strong>, <strong>c</strong>, the following identity holds: |<strong>abc</strong>| = (<strong>a</strong> × <strong>b</strong>) · <strong>c</strong> .</p>
<p class="qpara"><span class="green">7.</span> Explain why the volume of the tetrahedron with side vectors <strong>a</strong>, <strong>b</strong>, <strong>c</strong> (see <a href="C11_chapter6.xhtml#f6_2">Figure 6.2</a>) is given by |<strong>abc</strong>|<em>/</em>6.</p>
<p class="qpara"><span class="green">8.</span> Demonstrate the four interpretations of matrix–matrix multiplication by taking the following matrix–matrix multiplication code, rearranging the nested loops, and interpreting the resulting code in terms of matrix and vector operations.</p>
<pre class="pre">function mat-mult(in a[m][p], in b[p][n], out c[m][n]) {<br/>  // the array c is initialized to zero<br/>  for i = 1 to m<br/>    for j = 1 to n<br/>      for k = 1 to p<br/>        c[i][j] += a[i][k] * b[k][j]<br/>}</pre>
<p class="qpara"><span class="green">9.</span> <span aria-label="125" epub:type="pagebreak" id="pg_125" role="doc-pagebreak"/>Prove that if <strong>A</strong>, <strong>Q</strong>, and <strong>D</strong> satisfy Equation (6.14), <strong>v</strong> is the <em>i</em>th column of <strong>Q</strong>, and λ is the <em>i</em>th entry on the diagonal of <strong>D</strong>, then <strong>v</strong> is an eigenvector of <strong>A</strong> with eigenvalue λ.</p>
<p class="qpara1"><span class="green">10.</span> Prove that if <strong>A</strong>, <strong>Q</strong>,and <strong>D</strong> satisfy Equation (6.14), the eigenvalues of <strong>A</strong> are all distinct, and <strong>v</strong> is an eigenvector of <strong>A</strong> with eigenvalue λ, then for some <em>i</em>, <strong>v</strong> is the <em>i</em>th row of <strong>Q</strong> and λ is the <em>i</em>th entry on the diagonal of <strong>D</strong>.</p>
<p class="qpara1"><span class="green">11.</span> Given the (<em>x, y</em>) coordinates of the three vertices of a 2D triangle, explain why the area is given by</p>
<div class="disp-formula">
<m:math alttext=""><m:mrow><m:mfrac><m:mrow><m:mn>1</m:mn></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:mfrac><m:mrow><m:mo>|</m:mo><m:mtable><m:mtr><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>0</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>x</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>0</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>1</m:mn></m:mrow></m:msub></m:mtd><m:mtd><m:msub><m:mrow><m:mi>y</m:mi></m:mrow><m:mrow><m:mn>2</m:mn></m:mrow></m:msub></m:mtd></m:mtr><m:mtr><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd><m:mtd><m:mn>1</m:mn></m:mtd></m:mtr></m:mtable><m:mo>|</m:mo></m:mrow><m:mn>.</m:mn></m:mrow></m:math>
</div>
</section>
</section>
</body>
</html>